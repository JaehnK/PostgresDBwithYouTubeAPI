from abc import ABC, abstractmethod
from typing import Dict, List, Optional, Any
from dataclasses import dataclass, field
import os
import time
import logging
from pathlib import Path

from dotenv import load_dotenv
from googleapiclient.discovery import build
from googleapiclient.errors import HttpError

from ..YouTubeConfig import YouTubeConfig
from ..interfaces import ICommentCollector


# ==================== ë¬´ì œí•œ ëŒ“ê¸€ ìˆ˜ì§‘ê¸° êµ¬í˜„ ====================
class YouTubeCommentCollector(ICommentCollector):
    """YouTube APIë¥¼ ì‚¬ìš©í•œ ë¬´ì œí•œ ëŒ“ê¸€ ìˆ˜ì§‘ê¸° (ëª¨ë“  ëŒ“ê¸€ê³¼ ëŒ€ëŒ“ê¸€ ìˆ˜ì§‘)"""
    
    def __init__(self, config: YouTubeConfig):
        self.config = config
        self.youtube = build('youtube', 'v3', developerKey=config.api_key)
        self.quota_usage = 0
        self.last_call_time = 0
        self.logger = logging.getLogger(__name__)
    
    def _rate_limit(self):
        """API í˜¸ì¶œ ì œí•œ"""
        current_time = time.time()
        time_since_last = current_time - self.last_call_time
        
        if time_since_last < self.config.rate_limit_delay:
            time.sleep(self.config.rate_limit_delay - time_since_last)
        
        self.last_call_time = time.time()
    
    def _check_quota(self, cost: int = 1) -> bool:
        """í• ë‹¹ëŸ‰ í™•ì¸ ë° API í‚¤ ìˆœí™˜"""
        if self.quota_usage + cost > self.config.quota_limit_per_day:
            self.logger.warning(f"í• ë‹¹ëŸ‰ í•œê³„ ë„ë‹¬: {self.quota_usage}/{self.config.quota_limit_per_day}")
            
            # API í‚¤ ë³€ê²½ ì‹œë„
            if self.config._change_api():
                # ìƒˆë¡œìš´ API í‚¤ë¡œ YouTube í´ë¼ì´ì–¸íŠ¸ ì¬ìƒì„±
                self.youtube = build('youtube', 'v3', developerKey=self.config.api_key)
                self.quota_usage = 0  # í• ë‹¹ëŸ‰ ë¦¬ì…‹
                self.logger.info("ìƒˆë¡œìš´ API í‚¤ë¡œ ì „í™˜ ì™„ë£Œ")
                return True
            else:
                raise Exception(f"ëª¨ë“  API í‚¤ì˜ ì¼ì¼ í• ë‹¹ëŸ‰ì´ ì´ˆê³¼ë˜ì—ˆìŠµë‹ˆë‹¤.")
        return True
    
    def _handle_api_error(self, error: HttpError, operation: str):
        """API ì˜¤ë¥˜ ì²˜ë¦¬ ë° í‚¤ ìˆœí™˜"""
        if error.resp.status == 403:
            error_content = error.content.decode('utf-8') if hasattr(error, 'content') else str(error)
            if 'quotaExceeded' in error_content:
                self.logger.warning(f"{operation} ì¤‘ í• ë‹¹ëŸ‰ ì´ˆê³¼ ê°ì§€")
                if self.config._change_api():
                    # ìƒˆë¡œìš´ API í‚¤ë¡œ YouTube í´ë¼ì´ì–¸íŠ¸ ì¬ìƒì„±
                    self.youtube = build('youtube', 'v3', developerKey=self.config.api_key)
                    self.quota_usage = 0
                    return True  # ì¬ì‹œë„ ê°€ëŠ¥
                else:
                    raise Exception("ëª¨ë“  API í‚¤ì˜ í• ë‹¹ëŸ‰ì´ ì´ˆê³¼ë˜ì—ˆìŠµë‹ˆë‹¤.")
        return False  # ì¬ì‹œë„ ë¶ˆê°€
    
    def extract_comment_data(self, item: Dict, video_id: str, is_reply: bool = False, parent_id: str = '') -> Dict:
        """ëŒ“ê¸€ ë°ì´í„° ì¶”ì¶œ - í†µí•© ë²„ì „"""
        if is_reply:
            snippet = item['snippet']
        else:
            snippet = item['snippet']['topLevelComment']['snippet']
        
        return {
            'comment_id': item['id'],
            'video_id': video_id,
            'author': snippet['authorDisplayName'],
            'author_channel_id': snippet.get('authorChannelId', {}).get('value', ''),
            'comment_text': snippet['textDisplay'],
            'text_original': snippet['textOriginal'],
            'like_count': snippet['likeCount'],
            'published_at': snippet['publishedAt'],
            'updated_at': snippet['updatedAt'],
            'reply_count': item['snippet'].get('totalReplyCount', 0) if not is_reply else 0,
            'is_reply': is_reply,
            'parent_id': parent_id,
            'reply_depth': 1 if is_reply and parent_id else 0
        }
    
    def get_all_replies(self, parent_id: str, video_id: str) -> List[Dict]:
        """íŠ¹ì • ëŒ“ê¸€ì˜ ëª¨ë“  ë‹µê¸€ ìˆ˜ì§‘ (ë¬´ì œí•œ)"""
        all_replies = []
        next_page_token = None
        max_retries = self.config.max_retries
        page_count = 0
        
        self.logger.debug(f"ë‹µê¸€ ìˆ˜ì§‘ ì‹œì‘: ëŒ“ê¸€ {parent_id}")
        
        while True:
            retry_count = 0
            while retry_count < max_retries:
                try:
                    self._check_quota(1)
                    self._rate_limit()
                    
                    request = self.youtube.comments().list(
                        part='snippet',
                        parentId=parent_id,
                        maxResults=100,  # ìµœëŒ€ê°’ ì‚¬ìš©
                        pageToken=next_page_token if next_page_token else None
                    )
                    
                    response = request.execute()
                    self.quota_usage += 1
                    page_count += 1
                    
                    page_replies = 0
                    for item in response.get('items', []):
                        reply_data = self.extract_comment_data(item, video_id, is_reply=True, parent_id=parent_id)
                        all_replies.append(reply_data)
                        page_replies += 1
                    
                    if page_replies > 0:
                        self.logger.debug(f"ë‹µê¸€ í˜ì´ì§€ {page_count}: {page_replies}ê°œ (ì´ {len(all_replies)}ê°œ)")
                    
                    next_page_token = response.get('nextPageToken')
                    if not next_page_token:
                        if len(all_replies) > 0:
                            self.logger.info(f"ë‹µê¸€ ìˆ˜ì§‘ ì™„ë£Œ: ëŒ“ê¸€ {parent_id} - ì´ {len(all_replies)}ê°œ")
                        return all_replies
                    break  # ì„±ê³µì‹œ ì¬ì‹œë„ ë£¨í”„ ì¢…ë£Œ
                        
                except HttpError as e:
                    if e.resp.status == 404:
                        self.logger.debug(f"ëŒ“ê¸€ {parent_id}ì˜ ë‹µê¸€ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                        return all_replies
                    elif self._handle_api_error(e, "ë‹µê¸€ ìˆ˜ì§‘"):
                        # API í‚¤ê°€ ë³€ê²½ë˜ì—ˆìœ¼ë©´ ì¬ì‹œë„
                        retry_count += 1
                        continue
                    else:
                        self.logger.error(f"ë‹µê¸€ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
                        return all_replies
                        
                except Exception as e:
                    retry_count += 1
                    if retry_count >= max_retries:
                        self.logger.error(f"ë‹µê¸€ ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜ (ìµœëŒ€ ì¬ì‹œë„ ì´ˆê³¼): {e}")
                        return all_replies
                    
                    self.logger.warning(f"ë‹µê¸€ ìˆ˜ì§‘ ì¬ì‹œë„ {retry_count}/{max_retries}: {e}")
                    time.sleep(self.config.retry_delay * retry_count)
        
        return all_replies
    
    def collect_all_comments(self, video_id: str) -> List[Dict[str, Any]]:
        """ëª¨ë“  ëŒ“ê¸€ê³¼ ëŒ€ëŒ“ê¸€ì„ ì™„ì „íˆ ìˆ˜ì§‘ (ë¬´ì œí•œ)"""
        self.logger.info(f"ğŸš€ ë¹„ë””ì˜¤ ID: {video_id} - ë¬´ì œí•œ ëŒ“ê¸€ ìˆ˜ì§‘ ì‹œì‘")
        
        all_comments = []
        next_page_token = None
        page_count = 0
        max_retries = self.config.max_retries
        total_threads_processed = 0
        total_replies_collected = 0
        
        while True:
            retry_count = 0
            while retry_count < max_retries:
                try:
                    self._check_quota(1)
                    self._rate_limit()
                    
                    request = self.youtube.commentThreads().list(
                        part='snippet,replies',
                        videoId=video_id,
                        maxResults=100,  # ìµœëŒ€ê°’ ì‚¬ìš©
                        order='time',
                        pageToken=next_page_token if next_page_token else None
                    )
                    
                    response = request.execute()
                    self.quota_usage += 1
                    page_count += 1
                    page_comments = 0
                    page_replies = 0
                    
                    for item in response.get('items', []):
                        total_threads_processed += 1
                        
                        # 1. ìµœìƒìœ„ ëŒ“ê¸€ ì¶”ê°€
                        top_comment = self.extract_comment_data(item, video_id)
                        all_comments.append(top_comment)
                        page_comments += 1
                        
                        # 2. API ì‘ë‹µì— í¬í•¨ëœ ë‹µê¸€ë“¤ ì²˜ë¦¬
                        api_replies = []
                        if 'replies' in item:
                            for reply in item['replies']['comments']:
                                reply_data = self.extract_comment_data(reply, video_id, is_reply=True, parent_id=item['id'])
                                api_replies.append(reply_data)
                                all_comments.append(reply_data)
                                page_comments += 1
                                page_replies += 1
                        
                        # 3. ë‹µê¸€ì´ ë” ìˆëŠ” ê²½ìš° ëª¨ë“  ë‹µê¸€ ìˆ˜ì§‘ (ë¬´ì œí•œ)
                        total_reply_count = item['snippet']['totalReplyCount']
                        if total_reply_count > len(api_replies):
                            self.logger.info(f"ğŸ“ ëŒ“ê¸€ {item['id']}: {total_reply_count}ê°œ ë‹µê¸€ ì¤‘ {len(api_replies)}ê°œë§Œ ë¡œë“œë¨")
                            self.logger.info(f"   ğŸ”„ ë‚˜ë¨¸ì§€ {total_reply_count - len(api_replies)}ê°œ ë‹µê¸€ ìˆ˜ì§‘ ì¤‘...")
                            
                            # ëª¨ë“  ë‹µê¸€ ë³„ë„ ìˆ˜ì§‘ (ë¬´ì œí•œ)
                            complete_replies = self.get_all_replies(item['id'], video_id)
                            
                            # API ì‘ë‹µì— ì´ë¯¸ í¬í•¨ëœ ë‹µê¸€ ì œì™¸
                            api_reply_ids = {reply['comment_id'] for reply in api_replies}
                            new_replies = [reply for reply in complete_replies if reply['comment_id'] not in api_reply_ids]
                            
                            all_comments.extend(new_replies)
                            page_comments += len(new_replies)
                            total_replies_collected += len(new_replies)
                            
                            if len(new_replies) > 0:
                                self.logger.info(f"   âœ… ì¶”ê°€ ë‹µê¸€ {len(new_replies)}ê°œ ìˆ˜ì§‘ ì™„ë£Œ")
                    
                    # í˜ì´ì§€ ì§„í–‰ìƒí™© ë¡œê·¸
                    self.logger.info(f"ğŸ“„ í˜ì´ì§€ {page_count}: {page_comments}ê°œ ëŒ“ê¸€ ìˆ˜ì§‘")
                    self.logger.info(f"   ğŸ“Š ëˆ„ì  í†µê³„: ì´ {len(all_comments):,}ê°œ ëŒ“ê¸€ ({total_threads_processed}ê°œ ìŠ¤ë ˆë“œ)")
                    
                    # ë‹¤ìŒ í˜ì´ì§€ í™•ì¸
                    next_page_token = response.get('nextPageToken')
                    if not next_page_token:
                        self.logger.info("ğŸ‰ ëª¨ë“  ëŒ“ê¸€ ë° ëŒ€ëŒ“ê¸€ ìˆ˜ì§‘ ì™„ë£Œ!")
                        break
                    
                    # ëŒ€ìš©ëŸ‰ ìˆ˜ì§‘ì‹œ ì¤‘ê°„ ì§„í–‰ìƒí™© í‘œì‹œ
                    if page_count % 10 == 0:
                        self.logger.info(f"â±ï¸  ì§„í–‰ìƒí™©: {page_count}í˜ì´ì§€ ì™„ë£Œ, {len(all_comments):,}ê°œ ëŒ“ê¸€ ìˆ˜ì§‘ë¨")
                    
                    break  # ì„±ê³µì‹œ ì¬ì‹œë„ ë£¨í”„ ì¢…ë£Œ
                        
                except HttpError as e:
                    if self._handle_api_error(e, "ëŒ“ê¸€ ìˆ˜ì§‘"):
                        # API í‚¤ê°€ ë³€ê²½ë˜ì—ˆìœ¼ë©´ ì¬ì‹œë„
                        retry_count += 1
                        continue
                    else:
                        self.logger.error(f"API ìš”ì²­ ì‹¤íŒ¨: {e}")
                        break
                        
                except Exception as e:
                    retry_count += 1
                    if retry_count >= max_retries:
                        self.logger.error(f"ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜ (ìµœëŒ€ ì¬ì‹œë„ ì´ˆê³¼): {e}")
                        break
                    
                    self.logger.warning(f"ëŒ“ê¸€ ìˆ˜ì§‘ ì¬ì‹œë„ {retry_count}/{max_retries}: {e}")
                    time.sleep(self.config.retry_delay * retry_count)
            
            # ì¬ì‹œë„ í•œê³„ ë„ë‹¬ ë˜ëŠ” ë‹¤ìŒ í˜ì´ì§€ ì—†ìŒ
            if not next_page_token or retry_count >= max_retries:
                break
        
        # ìµœì¢… ìˆ˜ì§‘ ê²°ê³¼ ìš”ì•½
        structure = self.analyze_comment_structure(all_comments)
        self.logger.info(f"ğŸ ë¹„ë””ì˜¤ {video_id} ìˆ˜ì§‘ ì™„ë£Œ:")
        self.logger.info(f"   ğŸ“Š ì´ ëŒ“ê¸€: {len(all_comments):,}ê°œ")
        self.logger.info(f"   ğŸ” ìµœìƒìœ„ ëŒ“ê¸€: {structure['top_level_comments']:,}ê°œ")
        self.logger.info(f"   ğŸ’¬ ë‹µê¸€: {structure['replies']:,}ê°œ")
        self.logger.info(f"   ğŸ§µ ë‹µê¸€ ìˆëŠ” ìŠ¤ë ˆë“œ: {structure['threads_with_replies']:,}ê°œ")
        self.logger.info(f"   ğŸ“ˆ ìŠ¤ë ˆë“œë‹¹ í‰ê·  ë‹µê¸€: {structure['average_replies_per_thread']}")
        self.logger.info(f"   ğŸ† ìµœëŒ€ ë‹µê¸€ ìŠ¤ë ˆë“œ: {structure['max_replies_per_thread']}ê°œ")
        
        return all_comments
    
    def analyze_comment_structure(self, comments: List[Dict[str, Any]]) -> Dict[str, Any]:
        """ëŒ“ê¸€ êµ¬ì¡° ìƒì„¸ ë¶„ì„"""
        analysis = {
            'total_comments': len(comments),
            'top_level_comments': 0,
            'replies': 0,
            'threads_with_replies': 0,
            'max_replies_per_thread': 0,
            'total_threads': 0,
            'average_replies_per_thread': 0,
            'reply_distribution': {},  # ë‹µê¸€ ìˆ˜ë³„ ìŠ¤ë ˆë“œ ë¶„í¬
            'most_replied_thread': None,  # ê°€ì¥ ë‹µê¸€ì´ ë§ì€ ìŠ¤ë ˆë“œ
            'total_likes': 0,
            'average_likes_per_comment': 0
        }
        
        if not comments:
            return analysis
        
        # ìµœìƒìœ„ ëŒ“ê¸€ë“¤ê³¼ ë‹µê¸€ë“¤ ë¶„ë¦¬
        top_level = [c for c in comments if not c['is_reply']]
        replies = [c for c in comments if c['is_reply']]
        
        analysis['top_level_comments'] = len(top_level)
        analysis['replies'] = len(replies)
        analysis['total_threads'] = len(top_level)
        
        # ì „ì²´ ì¢‹ì•„ìš” ìˆ˜ ê³„ì‚°
        analysis['total_likes'] = sum(c['like_count'] for c in comments)
        analysis['average_likes_per_comment'] = round(analysis['total_likes'] / len(comments), 2) if comments else 0
        
        # ë‹µê¸€ ë¶„ì„
        if replies:
            threads_with_replies = set()
            reply_counts = {}
            
            for reply in replies:
                parent_id = reply['parent_id']
                threads_with_replies.add(parent_id)
                reply_counts[parent_id] = reply_counts.get(parent_id, 0) + 1
            
            analysis['threads_with_replies'] = len(threads_with_replies)
            analysis['max_replies_per_thread'] = max(reply_counts.values()) if reply_counts else 0
            analysis['average_replies_per_thread'] = round(len(replies) / len(top_level), 2) if top_level else 0
            
            # ë‹µê¸€ ìˆ˜ë³„ ë¶„í¬ ê³„ì‚°
            reply_distribution = {}
            for count in reply_counts.values():
                reply_distribution[count] = reply_distribution.get(count, 0) + 1
            analysis['reply_distribution'] = reply_distribution
            
            # ê°€ì¥ ë‹µê¸€ì´ ë§ì€ ìŠ¤ë ˆë“œ ì°¾ê¸°
            if reply_counts:
                most_replied_parent = max(reply_counts.items(), key=lambda x: x[1])
                # í•´ë‹¹ ìµœìƒìœ„ ëŒ“ê¸€ ì°¾ê¸°
                most_replied_comment = next((c for c in top_level if c['comment_id'] == most_replied_parent[0]), None)
                if most_replied_comment:
                    analysis['most_replied_thread'] = {
                        'comment_id': most_replied_comment['comment_id'],
                        'author': most_replied_comment['author'],
                        'text': most_replied_comment['text_original'][:100] + ('...' if len(most_replied_comment['text_original']) > 100 else ''),
                        'reply_count': most_replied_parent[1],
                        'like_count': most_replied_comment['like_count']
                    }
        
        return analysis
    
    def get_collection_summary(self, video_id: str, comments: List[Dict[str, Any]]) -> Dict[str, Any]:
        """ìˆ˜ì§‘ ê²°ê³¼ ìš”ì•½ ì •ë³´"""
        structure = self.analyze_comment_structure(comments)
        
        # ì‹œê°„ëŒ€ë³„ ëŒ“ê¸€ ë¶„í¬
        from datetime import datetime
        hourly_distribution = {}
        daily_distribution = {}
        
        for comment in comments:
            try:
                dt = datetime.fromisoformat(comment['published_at'].replace('Z', '+00:00'))
                hour_key = f"{dt.hour:02d}:00"
                day_key = dt.strftime('%Y-%m-%d')
                
                hourly_distribution[hour_key] = hourly_distribution.get(hour_key, 0) + 1
                daily_distribution[day_key] = daily_distribution.get(day_key, 0) + 1
            except:
                continue
        
        # ìƒìœ„ ëŒ“ê¸€ (ì¢‹ì•„ìš” ìˆœ)
        top_comments = sorted(comments, key=lambda x: x['like_count'], reverse=True)[:10]
        
        return {
            'video_id': video_id,
            'collection_time': datetime.now().isoformat(),
            'quota_used': self.quota_usage,
            'structure_analysis': structure,
            'temporal_analysis': {
                'hourly_distribution': hourly_distribution,
                'daily_distribution': daily_distribution,
                'most_active_hour': max(hourly_distribution.items(), key=lambda x: x[1]) if hourly_distribution else None,
                'most_active_day': max(daily_distribution.items(), key=lambda x: x[1]) if daily_distribution else None
            },
            'top_comments': [
                {
                    'author': c['author'],
                    'text': c['text_original'][:100] + ('...' if len(c['text_original']) > 100 else ''),
                    'likes': c['like_count'],
                    'is_reply': c['is_reply'],
                    'published_at': c['published_at']
                }
                for c in top_comments
            ]
        }


# ==================== ì‚¬ìš© ì˜ˆì œ ====================
def main():
    """ë¬´ì œí•œ ëŒ“ê¸€ ìˆ˜ì§‘ê¸° ì‚¬ìš© ì˜ˆì œ"""
    
    # ë¡œê¹… ì„¤ì •
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s'
    )
    
    # ì„¤ì •
    config = YouTubeConfig(
        output_dir="./unlimited_comments",
        rate_limit_delay=0.5,  # ë¬´ì œí•œ ìˆ˜ì§‘ì‹œ ì ì ˆí•œ ì§€ì—°
        max_retries=5
    )
    
    if not config.validate():
        print("âŒ API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        print("í™˜ê²½ë³€ìˆ˜ì— YOUTUBE_API_KEY1, YOUTUBE_API_KEY2, ... ë¥¼ ì„¤ì •í•˜ì„¸ìš”.")
        return
    
    # ëŒ“ê¸€ ìˆ˜ì§‘ê¸° ìƒì„±
    collector = YouTubeCommentCollector(config)
    
    # í…ŒìŠ¤íŠ¸ ë¹„ë””ì˜¤ ID
    test_video_id = "dQw4w9WgXcQ"  # Rick Astley - Never Gonna Give You Up
    
    try:
        print(f"ğŸš€ ë¬´ì œí•œ ëŒ“ê¸€ ìˆ˜ì§‘ ì‹œì‘: {test_video_id}")
        
        # ëª¨ë“  ëŒ“ê¸€ ìˆ˜ì§‘
        all_comments = collector.collect_all_comments(test_video_id)
        
        # ìˆ˜ì§‘ ê²°ê³¼ ìš”ì•½
        summary = collector.get_collection_summary(test_video_id, all_comments)
        
        print("\n" + "="*60)
        print("ğŸ“Š ìˆ˜ì§‘ ê²°ê³¼ ìš”ì•½")
        print("="*60)
        print(f"ì´ ëŒ“ê¸€ ìˆ˜: {summary['structure_analysis']['total_comments']:,}ê°œ")
        print(f"ìµœìƒìœ„ ëŒ“ê¸€: {summary['structure_analysis']['top_level_comments']:,}ê°œ")
        print(f"ë‹µê¸€: {summary['structure_analysis']['replies']:,}ê°œ")
        print(f"ì‚¬ìš©ëœ í• ë‹¹ëŸ‰: {summary['quota_used']}ì ")
        
        if summary['structure_analysis']['most_replied_thread']:
            most_replied = summary['structure_analysis']['most_replied_thread']
            print(f"ê°€ì¥ ì¸ê¸° ìŠ¤ë ˆë“œ: {most_replied['reply_count']}ê°œ ë‹µê¸€")
            print(f"  ì‘ì„±ì: {most_replied['author']}")
            print(f"  ë‚´ìš©: {most_replied['text']}")
        
        if summary['temporal_analysis']['most_active_hour']:
            active_hour = summary['temporal_analysis']['most_active_hour']
            print(f"ê°€ì¥ í™œë°œí•œ ì‹œê°„: {active_hour[0]} ({active_hour[1]}ê°œ ëŒ“ê¸€)")
        
        # CSV ì €ì¥
        import pandas as pd
        df = pd.DataFrame(all_comments)
        output_file = f"./unlimited_comments_{test_video_id}_{int(time.time())}.csv"
        df.to_csv(output_file, index=False, encoding='utf-8-sig')
        print(f"ğŸ’¾ ëŒ“ê¸€ ë°ì´í„° ì €ì¥: {output_file}")
        
        print("\nğŸ‰ ë¬´ì œí•œ ëŒ“ê¸€ ìˆ˜ì§‘ ì™„ë£Œ!")
        
    except Exception as e:
        print(f"âŒ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()